{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Handling and Scientific Computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "from scipy.stats import shapiro, levene, ttest_ind, mannwhitneyu, chi2_contingency\n",
    "\n",
    "# Preprocessing and Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "file_path = r'\\Datasets\\application_data.csv'\n",
    "\n",
    "# Function to load data\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def detect_imbalance(data, target_column, threshold=0.10):\n",
    "    # Calculate the proportions of each class in the target column\n",
    "    class_counts = data[target_column].value_counts(normalize=True)\n",
    "    \n",
    "    # Check if any class proportion is less than the threshold\n",
    "    is_imbalanced = any(class_counts < threshold) or any(class_counts > (1 - threshold))\n",
    "    \n",
    "    # Print out the class proportions and whether the dataset is imbalanced\n",
    "    print(f\"Class proportions:\\n{class_counts}\")\n",
    "    print(f\"Dataset is imbalanced: {is_imbalanced}\")\n",
    "\n",
    "    # Define a list of colors, one for each class\n",
    "    colors = ['red', 'blue'] \n",
    "    \n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    class_counts.plot(kind='bar', color=colors[:len(class_counts)])\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.title('Histogram of Target Class Proportions')\n",
    "    plt.show()\n",
    "    \n",
    "    return is_imbalanced\n",
    "\n",
    "# Function to drop the 'SK_ID_CURR' ID column\n",
    "def drop_id_column(data):\n",
    "    data = data.drop(columns=['SK_ID_CURR'])\n",
    "    return data\n",
    "\n",
    "# Function to filter out columns with more than 25% missing values\n",
    "def filter_columns(data, threshold=0.25):\n",
    "    missing_proportions = data.isnull().mean()\n",
    "    columns_to_keep = missing_proportions[missing_proportions < threshold].index.tolist()\n",
    "    data = data[columns_to_keep]\n",
    "    return data, missing_proportions, columns_to_keep\n",
    "\n",
    "# Function to filter out rows with more than 25% missing values\n",
    "def filter_rows(data, threshold=0.25):\n",
    "    missing_value_proportion_per_row = data.isnull().mean(axis=1)\n",
    "    data = data.loc[missing_value_proportion_per_row <= threshold]\n",
    "    return data, missing_value_proportion_per_row\n",
    "\n",
    "# Function to print the missing data statistics\n",
    "def print_missing_data_stats(missing_proportions, columns_to_keep, missing_value_proportion_per_row):\n",
    "    print(\"Proportion of missing data per column:\")\n",
    "    print(missing_proportions)\n",
    "\n",
    "    print(\"\\nColumns with less than 25% missing data:\")\n",
    "    print(columns_to_keep)\n",
    "\n",
    "    rows_with_high_missing_values = missing_value_proportion_per_row[missing_value_proportion_per_row > 0.25]\n",
    "    print(f\"Number of rows with missing value proportion > 0.25: {len(rows_with_high_missing_values)}\")\n",
    "\n",
    "# Function to label encode object-type columns\n",
    "def label_encode_data(data):\n",
    "    le = LabelEncoder()\n",
    "    label_mappings = {}\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == object:\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "            label_mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    return data, label_mappings\n",
    "\n",
    "# Function to convert list of float columns to integers\n",
    "def convert_floats_to_ints(data, columns_list):\n",
    "    data[columns_list] = data[columns_list].astype('Int64')\n",
    "    return data\n",
    "\n",
    "# List of columns to convert from float to int\n",
    "lst_flt_to_int = ['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "                  'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "                  'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "                  'DAYS_LAST_PHONE_CHANGE','DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "                  'OBS_60_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "                  'OBS_30_CNT_SOCIAL_CIRCLE','CNT_FAM_MEMBERS']\n",
    "\n",
    "# Function to fill missing values with mode for all columns\n",
    "def fill_missing_with_mode(data):\n",
    "    # First, calculate the modes and store them in a dictionary\n",
    "    modes_dict = {}\n",
    "    for column in data.columns:\n",
    "        mode_value = data[column].mode()[0]\n",
    "        modes_dict[column] = mode_value\n",
    "    \n",
    "    # Now use the modes to fill in missing values\n",
    "    for column, mode_value in modes_dict.items():\n",
    "        data[column].fillna(mode_value, inplace=True)\n",
    "    return data, modes_dict\n",
    "\n",
    "# Function to check for normality\n",
    "def normality_test(group):\n",
    "    stat, p_value = shapiro(group)\n",
    "    return p_value > 0.05  # Assuming alpha is 0.05\n",
    "\n",
    "# Function to check for homogeneity of variances\n",
    "def homogeneity_test(group1, group2):\n",
    "    stat, p_value = levene(group1, group2)\n",
    "    return p_value > 0.05  # Assuming alpha is 0.05\n",
    "\n",
    "def decide_and_test(feature, data):\n",
    "    # If feature is categorical or binary, perform chi-square test\n",
    "    if data[feature].dtype == 'object' or data[feature].nunique() <= 50:\n",
    "        contingency_table = pd.crosstab(data[feature], data['TARGET'])\n",
    "        chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "        return 'Chi-Square', chi2, p_value\n",
    "    # If feature is numeric and continuous, perform t-test or Mann-Whitney test\n",
    "    elif data[feature].dtype in [np.float64, np.int64,np.int32] and data[feature].nunique() > 50:\n",
    "        group1 = data[data['TARGET'] == 0][feature].dropna()\n",
    "        group2 = data[data['TARGET'] == 1][feature].dropna()\n",
    "        # Check for normality and homogeneity of variances\n",
    "        if normality_test(group1) and normality_test(group2) and homogeneity_test(group1, group2):\n",
    "            stat, p_value = ttest_ind(group1, group2, equal_var=True)\n",
    "            return 'T-test', stat, p_value\n",
    "        else:\n",
    "            stat, p_value = mannwhitneyu(group1, group2)\n",
    "            return 'Mann-Whitney', stat, p_value\n",
    "    else:\n",
    "        # For features that do not meet any of the above conditions, no test is performed\n",
    "        return 'Other', None, None\n",
    "\n",
    "def statistical_significance_filter(data):\n",
    "    test_results = []\n",
    "    for feature in data.columns:\n",
    "        if feature != 'TARGET':  # Exclude the target variable\n",
    "            test_type, stat, p_value = decide_and_test(feature, data)\n",
    "            # Handle None values by not appending them to the results\n",
    "            if test_type != 'Other':\n",
    "                test_results.append({\n",
    "                    'Feature': feature,\n",
    "                    'Test Type': test_type,\n",
    "                    'Statistic': stat if stat is not None else 'N/A',\n",
    "                    'p-value': p_value if p_value is not None else 'N/A'\n",
    "                })\n",
    "    test_results_df = pd.DataFrame(test_results)\n",
    "    \n",
    "    # Format the p-values and statistics for readability\n",
    "    test_results_df['p-value'] = test_results_df['p-value'].apply(lambda x: f\"{x:.3f}\" if x != 'N/A' else x)\n",
    "    test_results_df['Statistic'] = test_results_df['Statistic'].apply(lambda x: f\"{x:.3f}\" if x != 'N/A' else x)\n",
    "    test_results_df['p-value'] = pd.to_numeric(test_results_df['p-value'], errors='coerce')\n",
    "\n",
    "    # Filter out the significant features\n",
    "    sign_features = test_results_df[test_results_df['p-value'] < 0.05]['Feature'].tolist()\n",
    "    data = data[sign_features + ['TARGET']]\n",
    "    \n",
    "    return data, test_results_df, sign_features\n",
    "\n",
    "def remove_multicollinearity(data, threshold=0.8):\n",
    "    # Calculate the correlation matrix\n",
    "    corr = data.corr()\n",
    "\n",
    "    # Create a boolean mask for features to drop\n",
    "    to_drop = set()\n",
    "    for i in range(len(corr.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr.iloc[i, j]) > threshold:\n",
    "                to_drop.add(corr.columns[i])\n",
    "\n",
    "    # Drop features from the data\n",
    "    data = data.drop(columns=to_drop)\n",
    "    return data, to_drop\n",
    "\n",
    "# Function to apply PCA on FLAG_DOCUMENT features\n",
    "def apply_pca_flag_documents(data, columns, n_components):\n",
    "    data_pca = data[columns]\n",
    "    scaler = StandardScaler()\n",
    "    data_pca_scaled = scaler.fit_transform(data_pca)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    principalComponents = pca.fit_transform(data_pca_scaled)\n",
    "\n",
    "    # Save the scaler and PCA objects for later use\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    joblib.dump(pca, 'pca.pkl')\n",
    "    \n",
    "    # Calculate the sum of explained variance ratios\n",
    "    explained_variance_sum = sum(pca.explained_variance_ratio_)\n",
    "    print(f\"Sum of explained variance ratios for FLAG_DOCUMENT: {explained_variance_sum:.3f}\")\n",
    "\n",
    "    # Creating a DataFrame with the PCA components\n",
    "    pca_df = pd.DataFrame(data=principalComponents, \n",
    "                          columns=[f'PC_flag_{i+1}' for i in range(n_components)],\n",
    "                          index=data.index)\n",
    "    # Drop the original PCA columns from the data and concatenate the new PCA components\n",
    "    return pd.concat([data.drop(columns=columns), pca_df], axis=1)\n",
    "\n",
    "# Function to preprocess and oversample data\n",
    "def preprocess_and_oversample(data):\n",
    "    # Separate input features and target\n",
    "    X = data.drop('TARGET', axis=1)\n",
    "    y = data['TARGET']\n",
    "\n",
    "    # Identify categorical columns that need to be one-hot encoded\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Create a column transformer with OneHotEncoder for categorical variables\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ],\n",
    "        remainder='passthrough'  # leave the rest of the columns untouched\n",
    "    )\n",
    "\n",
    "    # Apply column transformer to X\n",
    "    X_encoded = column_transformer.fit_transform(X)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the SMOTE object\n",
    "    smote = SMOTE(random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data only\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Retrieve the feature names from the column transformer\n",
    "    # This will be a list of all the new feature names after one-hot encoding\n",
    "    new_feature_names = column_transformer.get_feature_names_out()\n",
    "\n",
    "    # Create a DataFrame with the oversampled features\n",
    "    oversampled_features = pd.DataFrame(X_train_smote, columns=new_feature_names)\n",
    "\n",
    "    # Add the oversampled target variable to the DataFrame\n",
    "    oversampled_features['TARGET'] = y_train_smote\n",
    "\n",
    "    print('Count of each classes after oversampling:', oversampled_features['TARGET'].value_counts())\n",
    "    print('Sum of missing value count in dataset:', oversampled_features.isnull().sum().sum())\n",
    "\n",
    "    return oversampled_features, X_test, y_test\n",
    "\n",
    "# Function to train and evaluate the XGBoost classifier\n",
    "def train_and_evaluate(data, X_test, y_test):\n",
    "    # Separate input features and target variable\n",
    "    X = data.drop('TARGET',axis=1)\n",
    "    y = data['TARGET']\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Initialize the XGBoost classifier\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    \n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the predictions on test set\n",
    "    print('Test Metrics (Before oversampling):')\n",
    "    print('Accuracy Score:', round(accuracy_score(y_test, y_pred_test), 4))\n",
    "    print('Precision Score:', round(precision_score(y_test, y_pred_test), 4))\n",
    "    print('Recall Score:', round(recall_score(y_test, y_pred_test), 4))\n",
    "    print('F1 Score:', round(f1_score(y_test, y_pred_test), 4))\n",
    "    print('-----------------------------------')\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    # Evaluate the predictions\n",
    "    print('Validation Metrics (After oversampling):')\n",
    "    print('Accuracy Score:', round(accuracy_score(y_val, y_pred), 4))\n",
    "    print('Precision Score:', round(precision_score(y_val, y_pred), 4))\n",
    "    print('Recall Score:', round(recall_score(y_val, y_pred), 4))\n",
    "    print('F1 Score:', round(f1_score(y_val, y_pred), 4))\n",
    "    print('-----------------------------------')\n",
    "    \n",
    "    return clf  # Optionally return the trained model\n",
    "\n",
    "def select_best20_features(data,features_number):\n",
    "    # Assuming data is your preprocessed DataFrame and 'TARGET' is the target variable\n",
    "    X = data.drop('TARGET', axis=1)\n",
    "    y = data['TARGET']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the classifier\n",
    "    clf= RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Fit the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances\n",
    "    importances = clf.feature_importances_\n",
    "\n",
    "    # Sort feature importances in descending order and select the indices of the top 20\n",
    "    indices = importances.argsort()[-features_number:][::-1]\n",
    "\n",
    "    # If you need to get the feature names as well\n",
    "    feature_names = X_train.columns[indices]\n",
    "    \n",
    "    # Create a new DataFrame with only the selected columns\n",
    "    data = data[['TARGET'] + feature_names.tolist()]\n",
    "\n",
    "    return data, feature_names\n",
    "\n",
    "def train_and_evaluate_20_features(data, X_test, y_test):\n",
    "    # Separate input features and target variable\n",
    "    X = data.drop('TARGET',axis=1)\n",
    "    y = data['TARGET']\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Initialize the XGBoost classifier\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    \n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    # Evaluate the predictions\n",
    "    print('Classes of predictions',y_pred)\n",
    "    print('Validation Metrics (After oversampling and using best 20 features):')\n",
    "    print('Accuracy Score:', round(accuracy_score(y_val, y_pred), 4))\n",
    "    print('Precision Score:', round(precision_score(y_val, y_pred), 4))\n",
    "    print('Recall Score:', round(recall_score(y_val, y_pred), 4))\n",
    "    print('F1 Score:', round(f1_score(y_val, y_pred), 4))\n",
    "    print('-----------------------------------')\n",
    "\n",
    "    return clf  # Optionally return the trained model\n",
    "\n",
    "# List of columns on which to perform PCA\n",
    "pca_columns_1 = [\n",
    "       'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_6',\n",
    "       'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11',\n",
    "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class proportions:\n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n",
      "Dataset is imbalanced: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of explained variance ratios for FLAG_DOCUMENT: 0.711\n",
      "Count of each classes after oversampling: TARGET\n",
      "0    226132\n",
      "1    226132\n",
      "Name: count, dtype: int64\n",
      "Sum of missing value count in dataset: 0\n",
      "Test Metrics (Before oversampling):\n",
      "Accuracy Score: 0.9187\n",
      "Precision Score: 0.4109\n",
      "Recall Score: 0.0228\n",
      "F1 Score: 0.0433\n",
      "-----------------------------------\n",
      "Validation Metrics (After oversampling):\n",
      "Accuracy Score: 0.956\n",
      "Precision Score: 0.9974\n",
      "Recall Score: 0.9147\n",
      "F1 Score: 0.9542\n",
      "-----------------------------------\n",
      "Classes of predictions [1 1 1 ... 0 1 1]\n",
      "Validation Metrics (After oversampling and using best 20 features):\n",
      "Accuracy Score: 0.9548\n",
      "Precision Score: 0.9975\n",
      "Recall Score: 0.9124\n",
      "F1 Score: 0.953\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# existing pipeline steps\n",
    "data = load_data(file_path)\n",
    "detect_imbalance(data, 'TARGET')\n",
    "data = drop_id_column(data)\n",
    "data, missing_proportions, columns_to_keep = filter_columns(data)\n",
    "data, missing_value_proportion_per_row = filter_rows(data)\n",
    "data, label_mappings = label_encode_data(data)\n",
    "data = convert_floats_to_ints(data, lst_flt_to_int)\n",
    "data, modes_dict = fill_missing_with_mode(data)\n",
    "data, test_results_df, sign_features= statistical_significance_filter(data)\n",
    "data, to_drop = remove_multicollinearity(data)\n",
    "data = apply_pca_flag_documents(data, pca_columns_1, 7)\n",
    "data, X_test, y_test = preprocess_and_oversample(data)\n",
    "model = train_and_evaluate(data, X_test, y_test)\n",
    "data, feature_names = select_best20_features(data,20)\n",
    "# after selecting best 20 features  \n",
    "model= train_and_evaluate_20_features(data, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to predict the class of any customer after data pre-processing processes after raw data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_new_data_single_row(single_row, label_mappings):\n",
    "    # Ensure single_row is a Pandas Series\n",
    "    if not isinstance(single_row, pd.Series):\n",
    "        raise ValueError(\"single_row must be a pandas Series\")\n",
    "\n",
    "    # Copy the single data row\n",
    "    encoded_row = single_row.copy()\n",
    "\n",
    "    # Apply label encoding for each column\n",
    "    for col in label_mappings:\n",
    "        # Check if this column is in the new data and is categorical\n",
    "        if col in encoded_row.index:\n",
    "            # Get the value for the column\n",
    "            value = single_row[col]\n",
    "\n",
    "            # Check if the value is NaN (use pd.isna for robustness)\n",
    "            if pd.isna(value):\n",
    "                encoded_row[col] = -1  # or another strategy for handling NaNs\n",
    "            else:\n",
    "                # Try to get the corresponding label\n",
    "                try:\n",
    "                    encoded_row[col] = label_mappings[col][value]\n",
    "                except KeyError:\n",
    "                    # If the categorical value is not seen in the training set\n",
    "                    encoded_row[col] = -1  # or another strategy for unseen values\n",
    "    return encoded_row\n",
    "\n",
    "def fill_missing_values_for_single_row(single_row, modes_dict):\n",
    "    for column, mode_value in modes_dict.items():\n",
    "        if pd.isnull(single_row[column]):\n",
    "            single_row[column] = mode_value\n",
    "    return single_row\n",
    "\n",
    "def sign_features_selection(df):\n",
    "    df = df[sign_features + ['TARGET']]\n",
    "    return df\n",
    "\n",
    "def remove_multicollinearity_selection(df):\n",
    "    # Drop features from the data\n",
    "    df = df.drop(columns=to_drop)\n",
    "    return df\n",
    "\n",
    "def apply_pca_to_new_row(new_row, columns):\n",
    "    # Load the saved scaler and PCA\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    pca = joblib.load('pca.pkl')\n",
    "\n",
    "    # Extract the relevant features from the new row\n",
    "    new_row_pca = new_row[columns]\n",
    "    if isinstance(new_row_pca, pd.Series):\n",
    "        new_row_pca = new_row_pca.to_frame().transpose()\n",
    "\n",
    "    # Standardize and apply PCA to the new row\n",
    "    new_row_scaled = scaler.transform(new_row_pca)\n",
    "    new_row_principalComponents = pca.transform(new_row_scaled)\n",
    "\n",
    "    # Creating a DataFrame with the PCA components\n",
    "    pca_df = pd.DataFrame(data=new_row_principalComponents, \n",
    "                          columns=[f'PC_flag_{i+1}' for i in range(joblib.load('pca.pkl').n_components)]\n",
    "                          ,index=new_row.index)\n",
    "    # Drop the original PCA columns from the data and concatenate the new PCA components\n",
    "    return pd.concat([new_row.drop(columns=columns), pca_df], axis=1) \n",
    "\n",
    "def select_best20_features_row(df,features_number):\n",
    "\n",
    "    # Create a new DataFrame with only the selected columns\n",
    "    new_feature_names = [name.replace('remainder__', '') for name in feature_names]\n",
    "    df = df[['TARGET'] + new_feature_names]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction class of entered record:\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "def process_and_predict(file_path, row_index, label_mappings, modes_dict, model, lst_flt_to_int, pca_columns_1, feature_names, to_drop):\n",
    "    # Load the specific row from the dataset (To show the functionality of the functions)\n",
    "    data_row = pd.read_csv(file_path).iloc[row_index, :] # or we can also enter any record that has the properties in the dataset\n",
    "\n",
    "    # Sequentially apply all processing functions\n",
    "    data_row = drop_id_column(data_row)\n",
    "    data_row = encode_new_data_single_row(data_row, label_mappings)\n",
    "    data_row = convert_floats_to_ints(data_row, lst_flt_to_int)\n",
    "    data_row = fill_missing_values_for_single_row(data_row, modes_dict)\n",
    "    data_row = sign_features_selection(data_row)\n",
    "    data_row = remove_multicollinearity_selection(pd.DataFrame(data_row).T)\n",
    "    data_row = apply_pca_to_new_row(data_row, pca_columns_1)\n",
    "    data_row = select_best20_features_row(data_row, 20)\n",
    "\n",
    "    # Predict and return the class of the processed record\n",
    "    prediction = model.predict(np.array(data_row.drop('TARGET', axis=1)))\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "file_path = r'\\Datasets\\application_data.csv'\n",
    "row_index = 2  # For example, to process the third row (index 2)\n",
    "print('Prediction class of entered record:')\n",
    "prediction = process_and_predict(file_path, row_index, label_mappings, modes_dict, model, lst_flt_to_int, pca_columns_1, feature_names, to_drop)\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
